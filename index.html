<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="kbQVKXi3GKhAhC7J3uLcMOVLXgJXuCTpCdMf-n_QMzo"> <meta name="msvalidate.01" content="51FB1EA32655786C7508DF70FA0580C6"> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Wanzhou Liu / 刘万洲 </title> <meta name="author" content="Wanzhou Liu"> <meta name="description" content="A simple academic website for Wanzhou Liu. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="wanzhou, washu, academic-website"> <meta property="og:site_name" content="Wanzhou Liu / 刘万洲"> <meta property="og:type" content="website"> <meta property="og:title" content="Wanzhou Liu / 刘万洲 | About"> <meta property="og:url" content="https://wenzel-luis.github.io/"> <meta property="og:description" content="A simple academic website for Wanzhou Liu. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta property="og:image" content="assets/img/prof_pic.jpg"> <meta property="og:locale" content="en"> <meta name="twitter:card" content="summary"> <meta name="twitter:title" content="About"> <meta name="twitter:description" content="A simple academic website for Wanzhou Liu. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="twitter:image" content="assets/img/prof_pic.jpg"> <script type="application/ld+json">
    {
        "author":
        {
            "@type": "Person",
            "name": "Wanzhou Liu"
        },
        "url": "https://wenzel-luis.github.io/",
        "@type": "WebSite",
        "description": "A simple academic website for Wanzhou Liu. Based on [*folio](https://github.com/bogoli/-folio) design.
",
        "headline": "About",
        
        "name": "Wanzhou Liu",
        "@context": "https://schema.org"
    }
  </script> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%93%A1&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://wenzel-luis.github.io/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <div class="navbar-brand social"> <a href="mailto:%77%61%6E%7A%68%6F%75%6C%69%75@%6F%75%74%6C%6F%6F%6B.%63%6F%6D" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://www.linkedin.com/in/wanzhouliu" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="assets/pdf/CV_Wanzhou_Liu.pdf" target="_blank" title="CV"><i class="ai ai-cv"></i></a> </div> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">About <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/engagements/">Engagements </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/photos/">Photo Nook</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> Wanzhou Liu / 刘万洲 </h1> <p class="desc">MSCS Student at <a href="https://washu.edu/" rel="external nofollow noopener" target="_blank">WashU</a>.</p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/prof_pic-480.webp 480w,/assets/img/prof_pic-800.webp 800w,/assets/img/prof_pic-1400.webp 1400w," type="image/webp" sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img/prof_pic.jpg?1dd43aa1db8695f1b948850cddc13e7d" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="prof_pic.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"> <p>"I will give it back when I get there."</p> </div> </div> <div class="clearfix"> <p>Welcome to my website! I am currently a master’s student in Computer Science at <a href="https://washu.edu/" rel="external nofollow noopener" target="_blank">WashU</a>, and am grateful to become a member of <a href="https://mvrl.cse.wustl.edu/" rel="external nofollow noopener" target="_blank">MVRL</a>, supervised by <a href="https://engineering.washu.edu/faculty/Nathan-Jacobs.html" rel="external nofollow noopener" target="_blank">Prof. Nathan Jacobs</a>. I am also fortunate to collaborate with <a href="https://www.bu.edu/eng/profile/ohn-bar-eshed/" rel="external nofollow noopener" target="_blank">Prof. Eshed Ohn-Bar</a> at <a href="https://www.bu.edu/" rel="external nofollow noopener" target="_blank">Boston University</a>. Previously, I received my BEng from <a href="https://www.qdu.edu.cn/" rel="external nofollow noopener" target="_blank">Qingdao University</a>.</p> <p>I am intrigued by cutting-edge computer vision techniques, including computational photography, 3D spatiotemporal visual perception, multimodal language models, and generative models. I pursue both theoretical and practical innovations, valuing simplicity, efficiency, and scalability in impactful research.</p> <p>I look up to <a href="https://jeremy.fast.ai/" rel="external nofollow noopener" target="_blank">Prof. Jeremy Howard</a> as my philosophical mentor, and my ultimate dream is to establish a nonprofit organization akin to <a href="https://en.wikipedia.org/wiki/Fast.ai" rel="external nofollow noopener" target="_blank">Fast.ai</a>. However, the more practical way for me before that is to help others as much as possible. If you have any questions or collaborations in mind, please feel free to reach out!</p> <p>Aside from research, I find great joy in literature and photography. You can find some of my photos tucked away in a quiet corner of this web. :)</p> </div> <h2> <a href="/news/" style="color: inherit">News</a> </h2> <div class="news"> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">May 18, 2024</th> <td> Joined <a href="https://eshed1.github.io/" rel="external nofollow noopener" target="_blank">Human-to-Everything (H2X)</a> lab in Boston as a visiting scholar. </td> </tr> <tr> <th scope="row" style="width: 20%">Aug 26, 2023</th> <td> Started my academic journey at <a href="https://washu.edu/" rel="external nofollow noopener" target="_blank">WashU</a>. </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">Selected Publications</a> </h2> <span style="font-size: 0.9em;">Symbol * or † represents equal contribution or advising.</span> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/passingdriving-480.webp 480w,/assets/img/publication_preview/passingdriving-800.webp 800w,/assets/img/publication_preview/passingdriving-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/passingdriving.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="passingdriving.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="passingdriving" class="col-sm-8"> <div class="title">Is LLM a Good Driver?</div> <div class="author"> Maolin Wei<sup>*</sup>, <strong>Wanzhou Liu<sup>*</sup></strong>, and Eshed Ohn-Bar </div> <div class="periodical"> <em>Under review</em> </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>Existing research in multimodal large language models (MLLMs) has focused on understanding spatial relationships in images, but there is less emphasis on understanding model reasoning over actions to take in real-world scenarios, such as following traffic rules and regulations in autonomous driving. In this paper, we evaluate LLMs and MLLMs for this novel task to assess their understanding and application of traffic rules, decision-making, and right-of-way in various scenarios. Using a newly developed dataset tailored for these challenges, we conduct a thorough examination of state-of-the-art LLMs and MLLMs, focusing on their ability to answer complex, context-specific questions related to traffic situations. Our findings show that while these models can handle basic questions effectively, they struggle with more nuanced decision-making tasks that require integrating both visual and textual information. This reveals critical limitations in their capability to handle real-world traffic scenarios accurately. To promote further research, we will make our dataset, code, and models publicly available. We hope this work inspires progress in developing more reliable AI systems for autonomous driving and robotics.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/declutternerf-480.webp 480w,/assets/img/publication_preview/declutternerf-800.webp 800w,/assets/img/publication_preview/declutternerf-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/declutternerf.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="declutternerf.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="declutternerf" class="col-sm-8"> <div class="title">DeclutterNeRF: Generative-Free 3D Scene Recovery for Occlusion Removal</div> <div class="author"> <strong>Wanzhou Liu</strong>, Zhexiao Xiong, Xinyu Li, and Nathan Jacobs </div> <div class="periodical"> <em>Under review, coming soon!</em> </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>Neural Radiance Fields (NeRF) have gained significant attention due to their high-quality rendering and accurate scene reconstruction. The ability to flexibly remove occlusions while preserving the details of the remaining scene can greatly enhance NeRF’s robustness and applicability. However, rendering a scene after occlusion removal introduces a fundamental challenge: reconstructing 3D structures from incomplete image information. Existing approaches typically rely on generative priors to complete missing regions, introducing additional computational complexity and potential artifacts. In this paper, we propose DeclutterNeRF, a novel approach for occlusion removal and scene reconstruction that operates without generative priors or significant computational overhead. Our method achieves state-of-the-art performance in occlusion-free scene reconstruction, offering a more lightweight and interpretable alternative to existing generative-based solutions. Additionally, we highlight key challenges in occlusion and object removal tasks and introduce a new occlusion dataset, which can serve as a benchmark for future research. We hope this work prompts a rethinking of NeRF’s approach in today’s landscape where its originally concise and neat functionality and structure are becoming complex and unwieldy.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ICCAID</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/cyclegan-480.webp 480w,/assets/img/publication_preview/cyclegan-800.webp 800w,/assets/img/publication_preview/cyclegan-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/cyclegan.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="cyclegan.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="liu2022time" class="col-sm-8"> <div class="title">As Time Goes By: Dynamic Face Aging Method Using CycleGAN</div> <div class="author"> <strong>Wanzhou Liu</strong> </div> <div class="periodical"> <em>In International Conference on Computer Graphics, Artificial Intelligence, and Data Processing (ICCAID)</em> , 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/121681C.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a> <a href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/12168/121681C/As-time-goes-by%E2%80%93dynamic-face-aging-method-using/10.1117/12.2631420.full" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="abstract hidden"> <p>Image-to-image style transfer using generative adversarial networks (GANs) has been extensively studied in computer vision, with numerous models proposed to enhance output performance. However, existing research predominantly focuses on improving model architecture and output quality, while the intermediate transformation process during style transfer remains underexplored. In this paper, we investigate the intermediate feature representations in style transfer based on CycleGAN and propose a novel approach to dynamically generate facial aging images by leveraging intermediate-layer gradients. Specifically, we utilize PyTorch’s autograd mechanism to compute and extract the gradients of non-leaf nodes within the network, facilitating a more interpretable and controllable style transition process. Experimental results on the AGFW-v2 dataset demonstrate the feasibility of our approach, revealing progressive changes in facial aging stages. Furthermore, the insights gained from processing intermediate-layer features can be extended to other tasks, such as photo enhancement and image dehazing, offering a new perspective for improving the controllability of generative models.</p> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2025 Wanzhou Liu. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?70d799092f862ad98c7876aa47712e20"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-C2MRE28BRB"></script> <script defer src="/assets/js/google-analytics-setup.js?12374742c4b1801ba82226e617af7e2d"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> </body> </html>