---
https://github.com/alshedivat/al-folio/blob/main/CUSTOMIZE.md#adding-a-new-publication
---

@string{cvpr = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}}
@string{iccvid = {IEEE/CVF International Conference on Computer Vision (ICCV)}}
@string{eccv = {European Conference on Computer Vision (ECCV)}}


@inproceedings{declutternerf,
  title={DeclutterNeRF: Generative-Free 3D Scene Recovery for Occlusion Removal},
  author={Liu, Wanzhou and Xiong, Zhexiao and Li, Xinyu and Jacobs, Nathan},
  abstract={Neural Radiance Fields (NeRF) have gained significant attention due to their high-quality rendering and accurate scene reconstruction. The ability to flexibly remove occlusions while preserving the details of the remaining scene can greatly enhance NeRFâ€™s robustness and applicability. However, rendering a scene after occlusion removal introduces a fundamental challenge: reconstructing 3D structures from incomplete image information. Existing approaches typically rely on generative priors to complete missing regions, introducing additional computational complexity and potential artifacts. In this paper, we propose DeclutterNeRF, a novel approach for occlusion removal and scene reconstruction that operates without generative priors or significant computational overhead. Our method achieves state-of-the-art performance in occlusion-free scene reconstruction, offering a more lightweight and interpretable alternative to existing generative-based solutions. Additionally, we highlight key challenges in occlusion and object removal tasks and introduce a new occlusion dataset, which can serve as a benchmark for future research. We hope this work prompts a rethinking of NeRF's approach in today's landscape where its originally concise and neat functionality and structure are becoming complex and unwieldy.},
  booktitle={Under review, coming soon!},
  year={2024},
  preview={declutternerf.png},
  selected={true}
}

@inproceedings{liu2022time,
  abbr={ICCAID},
  title={As Time Goes By: Dynamic Face Aging Method Using CycleGAN},
  author={Liu, Wanzhou},
  abstract={Image-to-image style transfer using generative adversarial networks (GANs) has been extensively studied in computer vision, with numerous models proposed to enhance output performance. However, existing research predominantly focuses on improving model architecture and output quality, while the intermediate transformation process during style transfer remains underexplored. In this paper, we investigate the intermediate feature representations in style transfer based on CycleGAN and propose a novel approach to dynamically generate facial aging images by leveraging intermediate-layer gradients. Specifically, we utilize PyTorch's autograd mechanism to compute and extract the gradients of non-leaf nodes within the network, facilitating a more interpretable and controllable style transition process. Experimental results on the AGFW-v2 dataset demonstrate the feasibility of our approach, revealing progressive changes in facial aging stages. Furthermore, the insights gained from processing intermediate-layer features can be extended to other tasks, such as photo enhancement and image dehazing, offering a new perspective for improving the controllability of generative models.},
  booktitle={International Conference on Computer Graphics, Artificial Intelligence, and Data Processing (ICCAID)},
  volume={12168},
  pages={290--296},
  year={2022},
  organization={SPIE},
  preview={cyclegan.png},
  pdf={121681C.pdf},
  website={https://www.spiedigitallibrary.org/conference-proceedings-of-spie/12168/121681C/As-time-goes-by--dynamic-face-aging-method-using/10.1117/12.2631420.full},
  selected={true}
}
